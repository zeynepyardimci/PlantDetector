{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "s0y1esU0o109"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets timm accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29K6UtAPpe3i"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ConvNextForImageClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "model_ckpt = \"facebook/convnext-base-224\"  # veya convnext-small, convnext-tiny\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(model_ckpt)\n",
    "model = ConvNextForImageClassification.from_pretrained(model_ckpt, num_labels=9,ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOT_jgrXqXYG"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "43OI_m7kszO6"
   },
   "outputs": [],
   "source": [
    "!pip install pyheif pillow-heif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xok2l9RyfIT"
   },
   "outputs": [],
   "source": [
    "pip install filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5_hOvFtos3aR"
   },
   "outputs": [],
   "source": [
    "import filetype\n",
    "import os\n",
    "\n",
    "def add_extension_with_filetype(file_path):\n",
    "    if os.path.splitext(file_path)[1] == '':\n",
    "        kind = filetype.guess(file_path)\n",
    "        if kind:\n",
    "            new_file = file_path + '.' + kind.extension\n",
    "            os.rename(file_path, new_file)\n",
    "            print(f\"Uzantı eklendi: {file_path} -> {new_file}\")\n",
    "            return new_file\n",
    "        else:\n",
    "            print(f\"Dosya tipi belirlenemedi: {file_path}\")\n",
    "            return file_path\n",
    "    else:\n",
    "        return file_path\n",
    "\n",
    "# Klasörü dolaşalım\n",
    "folder = '/content/drive/MyDrive/Raw'\n",
    "\n",
    "for root, _, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        add_extension_with_filetype(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZYbe3Rnjy6eG"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade datasets fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXBga6fgqbmF"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = \"/content/drive/MyDrive/Raw\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ConvNeXt için 224x224 input boyutu\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Toplam örnek sayısı: {len(dataset)}\")\n",
    "print(f\"Etiketler: {dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmiNxUlZznoR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "2Q1LYtfb0nM9"
   },
   "outputs": [],
   "source": [
    "from transformers import ConvNextForImageClassification, ConvNextFeatureExtractor\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Model ve feature extractor'ı indir\n",
    "model_name = \"facebook/convnext-tiny-224\"\n",
    "\n",
    "feature_extractor = ConvNextFeatureExtractor.from_pretrained(model_name)\n",
    "model = ConvNextForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLdNpBSG0zO9"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "# Hugging Face'den model yükleniyor\n",
    "model_ckpt = \"facebook/convnext-tiny-224\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_ckpt)\n",
    "\n",
    "# Preprocessing için dönüşüm (transform)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ConvNext 224x224 bekliyor\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "# Dataset yükleme\n",
    "dataset = ImageFolder(root=\"/content/drive/MyDrive/Raw\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGMtj4P-1-VZ"
   },
   "outputs": [],
   "source": [
    "# Örnek görüntü ve label kontrolü\n",
    "img, label = dataset[0]\n",
    "print(img.shape)  # torch.Size([3, 224, 224])\n",
    "print(label)      # 0 gibi sınıf indexi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZCIHSfq2FOB"
   },
   "source": [
    "modeli hazırla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJqA8lUl3wcu"
   },
   "outputs": [],
   "source": [
    "class_names = ['1. Potassium Deficiency', '2. Manganese Deficiency', '3. Magnesium Deficiency', '4. Black Scorch', '5. Leaf Spots', '6. Fusarium Wilt', '7. Rachis Blight', '8. Parlatoria Blanchardi', '9. Healthy sample']\n",
    "label2id = {label: idx for idx, label in enumerate(class_names)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkJjIIaX3BWu"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"facebook/convnext-base-384\",\n",
    "    num_labels=9,\n",
    "    label2id = {label: idx for idx, label in enumerate(dataset.class_to_idx)},\n",
    "    id2label = {idx: label for label, idx in dataset.class_to_idx.items()},\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QyxHmWu2HTN"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"facebook/convnext-base-384\",\n",
    "    num_labels=9,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvNLiymh6mdu"
   },
   "source": [
    "PyTorch ImageFolder → Hugging Face Dataset dönüşümü\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLJ1EdqYPnOR"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from datasets import Dataset, Features, ClassLabel\n",
    "from datasets.features import Image as HFDatasetImage\n",
    "from PIL import Image as PILImage\n",
    "from datasets import Value\n",
    "\n",
    "data_dir = \"/content/drive/MyDrive/Raw\"\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=None)\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for img_path, label in dataset.samples:\n",
    "    image_paths.append(img_path)\n",
    "    labels.append(label)\n",
    "\n",
    "dict_ds = {\n",
    "    \"image_path\": image_paths,\n",
    "    \"label\": labels\n",
    "}\n",
    "\n",
    "features = Features({\n",
    "    \"image_path\": Value(\"string\"),  \n",
    "    \"label\": ClassLabel(names=list(set(labels)))\n",
    "})\n",
    "\n",
    "\n",
    "hf_dataset = Dataset.from_dict(dict_ds, features=features)\n",
    "\n",
    "def safe_load_image_batch(example_batch):\n",
    "    images = []\n",
    "    for path in example_batch[\"image_path\"]:\n",
    "        try:\n",
    "            img = PILImage.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Hata dosyada: {path} -> {e}\")\n",
    "            img = None\n",
    "        images.append(img)\n",
    "    return {\"image\": images}\n",
    "\n",
    "hf_dataset = hf_dataset.map(\n",
    "    safe_load_image_batch,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    desc=\"Görüntüleri yükle\"\n",
    ")\n",
    "\n",
    "def filter_none_images(example):\n",
    "    return example[\"image\"] is not None\n",
    "\n",
    "hf_dataset = hf_dataset.filter(filter_none_images)\n",
    "\n",
    "print(f\"Temizlenmiş dataset hazır, toplam örnek sayısı: {len(hf_dataset)}\")\n",
    "print(hf_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSLKqo08R-98"
   },
   "outputs": [],
   "source": [
    "print(hf_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Z1gMlOEPR1BB"
   },
   "outputs": [],
   "source": [
    "def filter_none_images(example):\n",
    "    return example[\"image\"] is not None\n",
    "\n",
    "hf_dataset = hf_dataset.filter(filter_none_images)\n",
    "print(f\"Temizlenmiş dataset, toplam örnek sayısı: {len(hf_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o5paXqt4Xch"
   },
   "source": [
    "Eğitim Kodu (Trainer ile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8_8eQViEJB6e"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "JX6vrUx1Mc5C"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlmIlVkc4YIl"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, AutoImageProcessor, ConvNextForImageClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torchvision.datasets import ImageFolder\n",
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1. Image processor ve model seçimi\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "\n",
    "# Doğru sınıf sayısı ile model tanımı\n",
    "data_dir = \"/content/drive/MyDrive/Raw\"\n",
    "torch_dataset = ImageFolder(root=data_dir)\n",
    "num_classes = len(torch_dataset.classes)\n",
    "\n",
    "model = ConvNextForImageClassification.from_pretrained(\n",
    "    \"facebook/convnext-tiny-224\",\n",
    "    num_labels=num_classes,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# 2. Metrik fonksiyonu\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 3. Dataset yükle\n",
    "image_paths = [path for path, _ in torch_dataset.samples]\n",
    "labels = [label for _, label in torch_dataset.samples]\n",
    "dict_ds = {\"image_path\": image_paths, \"label\": labels}\n",
    "hf_dataset = Dataset.from_dict(dict_ds)\n",
    "\n",
    "# 4. Görselleri yükle (önceden resize edip tensor'a çeviriyoruz)\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def load_images(example_batch):\n",
    "    images = []\n",
    "    for path in example_batch[\"image_path\"]:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = image_transform(img)\n",
    "        images.append(img)\n",
    "    return {\"pixel_values\": images}\n",
    "\n",
    "hf_dataset = hf_dataset.map(load_images, batched=True, num_proc=1)\n",
    "\n",
    "# 5. Train/test ayır\n",
    "split_dataset = hf_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "\n",
    "# 6. transform fonksiyonu\n",
    "def transform(example_batch):\n",
    "    inputs = processor(images=example_batch[\"pixel_values\"], return_tensors=\"pt\")\n",
    "    example_batch[\"pixel_values\"] = list(inputs[\"pixel_values\"])\n",
    "    example_batch[\"labels\"] = example_batch[\"label\"]\n",
    "    return example_batch\n",
    "\n",
    "# Her iki subset'te ayrı ayrı transform uygula\n",
    "train_dataset = split_dataset[\"train\"].map(transform, batched=True)\n",
    "test_dataset = split_dataset[\"test\"].map(transform, batched=True)\n",
    "\n",
    "encoded_dataset = split_dataset.map(transform, batched=True)\n",
    "\n",
    "# 7. Eğitim argümanları\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./convnext-results\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True  # Colab için daha az bellek kullanımı\n",
    ")\n",
    "#data collator\n",
    "def data_collator(features):\n",
    "    pixel_values = torch.stack([f[\"pixel_values\"] for f in features])\n",
    "    labels = torch.tensor([f[\"labels\"] for f in features])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# 8. Trainer nesnesi (custom data collator ile!)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 9. Eğitimi başlat\n",
    "train_output = trainer.train()\n",
    "\n",
    "# 10. Metrikleri kaydet\n",
    "with open(\"train_metrics.json\", \"w\") as f:\n",
    "    json.dump(train_output.metrics, f, indent=4)\n",
    "\n",
    "eval_metrics = trainer.evaluate()\n",
    "with open(\"eval_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=4)\n",
    "\n",
    "# 11. Modeli kaydet\n",
    "trainer.save_model(\"./convnext-model\")\n",
    "processor.save_pretrained(\"./convnext-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ELMlC5JyKOrf"
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets torchvision scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "W5tGc1J5MAiD"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kX8RLoZhKTM3"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=\"/content/drive/MyDrive/Raw\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tO-i5U_bMOYj"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copytree(\"/content/drive/MyDrive/Raw\", \"/tmp/Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2ym_NOONE4G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from transformers import ConvNextForImageClassification, ConvNextImageProcessor, Trainer, TrainingArguments\n",
    "\n",
    "# 1. Veri yolu\n",
    "data_dir = \"/content/drive/MyDrive/Raw\" \n",
    "\n",
    "# 2. Görsel transformasyonları\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 3. Dataset ve split\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 4. Processor ve model\n",
    "processor = ConvNextImageProcessor.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "model = ConvNextForImageClassification.from_pretrained(\n",
    "    \"facebook/convnext-tiny-224\",\n",
    "    num_labels=len(dataset.classes),\n",
    "    id2label={i: c for i, c in enumerate(dataset.classes)},\n",
    "    label2id={c: i for i, c in enumerate(dataset.classes)},\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "# 5. Collate function — Trainer ile DataLoader\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    # processor, pil image listesi alır ve tensor döner\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# 6. Trainer'ın içine DataLoader koymuyoruz direkt Dataset veriyoruz,\n",
    "# Trainer kendi içinde batch ve collate yapıyor\n",
    "# Bu yüzden train_ds ve val_ds kullanacağız, sadece collate_fn'u Trainer'a veriyoruz\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "# 7. Eğitimi başlat\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMuUZLLdPC4D"
   },
   "source": [
    "yeni bir deneme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Kso3EHpwR_IX"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ebyDe72OSNNA"
   },
   "outputs": [],
   "source": [
    "pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTgbDN5Tn5Ws"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 18441160,
     "status": "ok",
     "timestamp": 1752930973275,
     "user": {
      "displayName": "ZEYNEP YARDIMCI",
      "userId": "08243208065676408191"
     },
     "user_tz": -180
    },
    "id": "8aRr5o9mRW03",
    "outputId": "1688fd79-164c-4ff9-8472-c849a8d6722b"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    ConvNextForImageClassification,\n",
    "    ConvNextImageProcessor,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import json\n",
    "from google.colab import drive\n",
    "\n",
    "# Google Drive'ı mount et (çalıştırdığında Drive'a erişim vereceksin)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Veri yolu\n",
    "data_dir = \"/content/drive/MyDrive/Raw\"  \n",
    "\n",
    "# Görsel transformasyonları\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset ve split\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Processor ve model\n",
    "processor = ConvNextImageProcessor.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "model = ConvNextForImageClassification.from_pretrained(\n",
    "    \"facebook/convnext-tiny-224\",\n",
    "    num_labels=len(dataset.classes),\n",
    "    id2label={i: c for i, c in enumerate(dataset.classes)},\n",
    "    label2id={c: i for i, c in enumerate(dataset.classes)},\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "# Collate function (batch olarak işleme için)\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Metrik fonksiyonu (accuracy, f1, precision, recall)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "# TrainingArguments (Kaydetme, logging ve değerlendirme ayarları)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/convnext-results3\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    save_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    # Early stopping için gerekenler\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",  \n",
    "    eval_strategy=\"steps\",       # 'epoch' da olabilir ama steps daha iyi erken durdurmada\n",
    "    eval_steps=100,                    # Kaç adımda bir validation yapılacağı\n",
    ")\n",
    "\n",
    "# Trainer nesnesi\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,  \n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=7)],  # patience: kaç defa artmazsa dursun\n",
    ")\n",
    "\n",
    "# Eğitimi başlat\n",
    "train_output = trainer.train()\n",
    "\n",
    "# Metrikleri kaydet (Drive içine)\n",
    "with open(\"/content/drive/MyDrive/train_metrics3.json\", \"w\") as f:\n",
    "    json.dump(train_output.metrics, f, indent=4)\n",
    "\n",
    "eval_metrics = trainer.evaluate()\n",
    "with open(\"/content/drive/MyDrive/eval_metrics3.json\", \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=4)\n",
    "\n",
    "# Model ve processor'ü kaydet (Drive içine)\n",
    "trainer.save_model(\"/content/drive/MyDrive/convnext-model3\")\n",
    "processor.save_pretrained(\"/content/drive/MyDrive/convnext-model3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv8uiMIOqg0S"
   },
   "source": [
    "convnext-base-224 modeli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "executionInfo": {
     "elapsed": 1736265,
     "status": "ok",
     "timestamp": 1753019888842,
     "user": {
      "displayName": "ZEYNEP YARDIMCI",
      "userId": "08243208065676408191"
     },
     "user_tz": -180
    },
    "id": "JoGgJ5zgqfL5",
    "outputId": "704ed895-5a20-4164-a23e-cd2c45b8db18"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    ConvNextForImageClassification,\n",
    "    ConvNextImageProcessor,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import json\n",
    "from google.colab import drive\n",
    "\n",
    "# Google Drive'ı mount et (Drive erişimi için)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Veri yolu\n",
    "data_dir = \"/content/drive/MyDrive/Raw\"  \n",
    "\n",
    "# Görsel transformasyonları\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset ve split\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Processor ve model (ConvNext Base versiyonu)\n",
    "processor = ConvNextImageProcessor.from_pretrained(\"facebook/convnext-base-224\")\n",
    "model = ConvNextForImageClassification.from_pretrained(\n",
    "    \"facebook/convnext-base-224\",\n",
    "    num_labels=len(dataset.classes),\n",
    "    id2label={i: c for i, c in enumerate(dataset.classes)},\n",
    "    label2id={c: i for i, c in enumerate(dataset.classes)},\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "# Collate function (batch olarak işleme için)\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Metrik fonksiyonu (accuracy, f1, precision, recall)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "# TrainingArguments (Kaydetme, logging ve değerlendirme ayarları)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/convnext-results-base\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,                   # GPU varsa aç, yoksa False yap\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    ")\n",
    "\n",
    "# Trainer nesnesi\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=7)],\n",
    ")\n",
    "\n",
    "# Eğitimi başlat\n",
    "train_output = trainer.train(resume_from_checkpoint=\"/content/drive/MyDrive/convnext-results-base/checkpoint-2800\")\n",
    "\n",
    "# Metrikleri kaydet\n",
    "with open(\"/content/drive/MyDrive/train_metrics_base.json\", \"w\") as f:\n",
    "    json.dump(train_output.metrics, f, indent=4)\n",
    "\n",
    "eval_metrics = trainer.evaluate()\n",
    "with open(\"/content/drive/MyDrive/eval_metrics_base.json\", \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=4)\n",
    "\n",
    "# Model ve processor'ü kaydet\n",
    "trainer.save_model(\"/content/drive/MyDrive/convnext-model-base\")\n",
    "processor.save_pretrained(\"/content/drive/MyDrive/convnext-model-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 233298,
     "status": "ok",
     "timestamp": 1752912301118,
     "user": {
      "displayName": "ZEYNEP YARDIMCI",
      "userId": "08243208065676408191"
     },
     "user_tz": -180
    },
    "id": "7oddVx2UovCB",
    "outputId": "5e39c148-14bb-4a81-fcff-09fd2ed5536a"
   },
   "outputs": [],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip cache purge\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11983,
     "status": "ok",
     "timestamp": 1752912370542,
     "user": {
      "displayName": "ZEYNEP YARDIMCI",
      "userId": "08243208065676408191"
     },
     "user_tz": -180
    },
    "id": "vYVndFYXs5tF",
    "outputId": "c3f1c067-9ed6-43f5-b1b8-601b9f22357b"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.53.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHLgz_d2WOij"
   },
   "source": [
    "Model Değerlendirme ve Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "executionInfo": {
     "elapsed": 58599,
     "status": "ok",
     "timestamp": 1752934818722,
     "user": {
      "displayName": "ZEYNEP YARDIMCI",
      "userId": "08243208065676408191"
     },
     "user_tz": -180
    },
    "id": "VqrtxcdGPEzt",
    "outputId": "65d7bf8d-36be-4fde-e476-ee4b3c0bff50"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer, AutoFeatureExtractor, ConvNextForImageClassification\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from google.colab import drive\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# WandB'yi kapatmak için:\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# 1. Google Drive'ı mount et\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# 2. Model ve Processor'ü yükle\n",
    "model_path = \"/content/drive/MyDrive/convnext-model3\"\n",
    "model = ConvNextForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoFeatureExtractor.from_pretrained(model_path)\n",
    "\n",
    "# 3. Test dataset (Raw klasöründeki veriyi tekrar yükle ve split)\n",
    "data_dir = \"/content/drive/MyDrive/Raw\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "_, test_size = int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))\n",
    "_, test_ds = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), test_size])\n",
    "\n",
    "# 4. Collate function (modelin beklentisine göre)\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# 5. Trainer ayarları\n",
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(output_dir=\"./test-eval\", per_device_eval_batch_size=8)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=collate_fn\n",
    ")\n",
    "\n",
    "# 6. Test tahmini\n",
    "outputs = trainer.predict(test_ds)\n",
    "y_pred = np.argmax(outputs.predictions, axis=1)\n",
    "y_true = outputs.label_ids\n",
    "\n",
    "# 7. Sınıf isimleri\n",
    "label_names = dataset.classes  \n",
    "\n",
    "# 8. Raporu oluştur\n",
    "active_labels = unique_labels(y_true, y_pred)\n",
    "active_label_names = [label_names[i] for i in active_labels]\n",
    "\n",
    "report = classification_report(y_true, y_pred, labels=active_labels, target_names=active_label_names, digits=4)\n",
    "# Accuracy hesapla\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Raporun sonuna accuracy'yi ekle\n",
    "report_with_accuracy = report + f\"\\nAccuracy: {accuracy:.4f}\\n\"\n",
    "\n",
    "print(report_with_accuracy)\n",
    "\n",
    "# 9. Google Drive'a kaydet\n",
    "save_path = \"/content/drive/MyDrive/model_sonuclari3/degerlendirme_raporu3.txt\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_with_accuracy)\n",
    "\n",
    "print(f\"\\nDeğerlendirme raporu başarıyla kaydedildi: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP3lu6StEkJCXiXVFTI2HoI",
   "gpuType": "T4",
   "mount_file_id": "1dEy-U1jO0wfS602wGI-7fQrEZY78_pKG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
